{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b4644e-d38c-464d-ace1-143f169b2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edd018bf-9432-4249-8526-969454f59788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.10.0 in ./anaconda3/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in ./anaconda3/lib/python3.11/site-packages (from scipy==1.10.0) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy==1.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287c4672-0957-472b-829a-69a15c299d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e77864-a0c2-43ea-8fb8-9b7697088764",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"Corona_NLP_train.csv\", encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24feb18-661d-4883-bd3a-7d6c19735e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41154  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41155  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2763fbff-ba7e-4107-a3f6-0db5bf694c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv(\"Corona_NLP_test.csv\", encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2324c9d0-69a1-47d5-81f2-8676403da93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>44953</td>\n",
       "      <td>NYC</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44954</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44956</td>\n",
       "      <td>Chicagoland</td>\n",
       "      <td>02-03-2020</td>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>44957</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>03-03-2020</td>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>3794</td>\n",
       "      <td>48746</td>\n",
       "      <td>Israel ??</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>3795</td>\n",
       "      <td>48747</td>\n",
       "      <td>Farmington, NM</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>3796</td>\n",
       "      <td>48748</td>\n",
       "      <td>Haverford, PA</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>3797</td>\n",
       "      <td>48749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>3798</td>\n",
       "      <td>48750</td>\n",
       "      <td>Arlington, Virginia</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserName  ScreenName             Location     TweetAt  \\\n",
       "0            1       44953                  NYC  02-03-2020   \n",
       "1            2       44954          Seattle, WA  02-03-2020   \n",
       "2            3       44955                  NaN  02-03-2020   \n",
       "3            4       44956          Chicagoland  02-03-2020   \n",
       "4            5       44957  Melbourne, Victoria  03-03-2020   \n",
       "...        ...         ...                  ...         ...   \n",
       "3793      3794       48746            Israel ??  16-03-2020   \n",
       "3794      3795       48747       Farmington, NM  16-03-2020   \n",
       "3795      3796       48748        Haverford, PA  16-03-2020   \n",
       "3796      3797       48749                  NaN  16-03-2020   \n",
       "3797      3798       48750  Arlington, Virginia  16-03-2020   \n",
       "\n",
       "                                          OriginalTweet           Sentiment  \n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
       "2     Find out how you can protect yourself and love...  Extremely Positive  \n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  \n",
       "...                                                 ...                 ...  \n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive  \n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative  \n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral  \n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative  \n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive  \n",
       "\n",
       "[3798 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9139be9-8750-4555-aa0f-5a8a144d5956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mohitsarin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mohitsarin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|@\\S+|#[A-Za-z0-9]+|\\$[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = re.sub(r'\\,{2,}', ' ', text)\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,\\']', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stopwords_set]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78b2cf1b-b543-4962-82ea-26e3346ed03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text2(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,\\']', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stopwords_set = set(stopwords.words('english'))\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stopwords_set]\n",
    "    return tokens\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|@\\S+|#[A-Za-z0-9]+|\\$[A-Za-z0-9]+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)\n",
    "    text = re.sub(r'\\,{2,}', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s.,\\']', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    preprocessed_text = ''.join(text)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac56ed1-cd54-4a50-b1e5-652f76a8e2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data=lambda text:clean_text(text)\n",
    "train_df[\"OriginalTweet\"]=train_df[\"OriginalTweet\"].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1078334d-3ad1-417a-9423-8d4ed474ef05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>and and</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me, ready to go at supermarket during the outb...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know it s getting tough when is rationing ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>well new used rift s are going for . on amazo...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0                                               and and              Neutral  \n",
       "1      advice talk to your neighbours family to excha...            Positive  \n",
       "2      coronavirus australia woolworths to give elder...            Positive  \n",
       "3      my food stock is not the only one which is emp...            Positive  \n",
       "4      me, ready to go at supermarket during the outb...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41152  airline pilots offering to stock supermarket s...             Neutral  \n",
       "41153  response to complaint not provided citing covi...  Extremely Negative  \n",
       "41154  you know it s getting tough when is rationing ...            Positive  \n",
       "41155  is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41156   well new used rift s are going for . on amazo...            Negative  \n",
       "\n",
       "[41157 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d7a8fbc-3135-441c-9220-454b1050b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data=lambda text:preprocess_text(text)\n",
    "train_df[\"text_prepro\"]=train_df[\"OriginalTweet\"].apply(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a439a37e-7341-4500-bc98-68613fa56844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>text_prepro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>and and</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>coronavirus australia woolworths to give elder...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronaviru australia woolworth give elderli , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>my food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>food stock one empti pleas , n't panic , enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>me, ready to go at supermarket during the outb...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>, readi go supermarket outbreak . 'm paranoid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41152</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>airlin pilot offer stock supermarket shelv loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41153</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>response to complaint not provided citing covi...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>respons complaint provid cite covid relat dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>you know it s getting tough when is rationing ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>know get tough ration toilet paper martinsvil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>wrong smell hand sanit start turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>well new used rift s are going for . on amazo...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>well new use rift go . amazon rn although norm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41157 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserName  ScreenName                      Location     TweetAt  \\\n",
       "0          3799       48751                        London  16-03-2020   \n",
       "1          3800       48752                            UK  16-03-2020   \n",
       "2          3801       48753                     Vagabonds  16-03-2020   \n",
       "3          3802       48754                           NaN  16-03-2020   \n",
       "4          3803       48755                           NaN  16-03-2020   \n",
       "...         ...         ...                           ...         ...   \n",
       "41152     44951       89903  Wellington City, New Zealand  14-04-2020   \n",
       "41153     44952       89904                           NaN  14-04-2020   \n",
       "41154     44953       89905                           NaN  14-04-2020   \n",
       "41155     44954       89906                           NaN  14-04-2020   \n",
       "41156     44955       89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \\\n",
       "0                                               and and              Neutral   \n",
       "1      advice talk to your neighbours family to excha...            Positive   \n",
       "2      coronavirus australia woolworths to give elder...            Positive   \n",
       "3      my food stock is not the only one which is emp...            Positive   \n",
       "4      me, ready to go at supermarket during the outb...  Extremely Negative   \n",
       "...                                                  ...                 ...   \n",
       "41152  airline pilots offering to stock supermarket s...             Neutral   \n",
       "41153  response to complaint not provided citing covi...  Extremely Negative   \n",
       "41154  you know it s getting tough when is rationing ...            Positive   \n",
       "41155  is it wrong that the smell of hand sanitizer i...             Neutral   \n",
       "41156   well new used rift s are going for . on amazo...            Negative   \n",
       "\n",
       "                                             text_prepro  \n",
       "0                                                         \n",
       "1      advic talk neighbour famili exchang phone numb...  \n",
       "2      coronaviru australia woolworth give elderli , ...  \n",
       "3      food stock one empti pleas , n't panic , enoug...  \n",
       "4      , readi go supermarket outbreak . 'm paranoid ...  \n",
       "...                                                  ...  \n",
       "41152  airlin pilot offer stock supermarket shelv loc...  \n",
       "41153  respons complaint provid cite covid relat dela...  \n",
       "41154  know get tough ration toilet paper martinsvil ...  \n",
       "41155                  wrong smell hand sanit start turn  \n",
       "41156  well new use rift go . amazon rn although norm...  \n",
       "\n",
       "[41157 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5135329d-7988-4b12-ac24-165b9d651a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Index 'documents': []\n"
     ]
    }
   ],
   "source": [
    "float_indexes = []\n",
    "for index, value in train_df['text_prepro'].items():\n",
    "    if isinstance(value, float):\n",
    "        float_indexes.append(index)\n",
    "print(\"Null Index 'documents':\", float_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57ab7032-63df-43c9-9789-97013c9b9046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Index 'documents': [0, 16, 186, 397, 583, 2190, 5946, 8803, 9169, 10946, 12410, 13452, 13777, 14425, 14840, 16342, 16924, 17761, 19828, 22994, 28549, 29888, 30345, 30473, 31293, 31440, 31627, 31657, 32455, 33587, 35563, 35565, 35752, 36983, 37646, 38226, 40511, 41141]\n"
     ]
    }
   ],
   "source": [
    "null_indexes = []\n",
    "for index, value in train_df['text_prepro'].items():\n",
    "    if pd.isnull(value) or value.strip() == \"\":\n",
    "        null_indexes.append(index)\n",
    "print(\"Null Index 'documents':\", null_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71c3ac95-08a7-4896-8842-013d28c6af1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(null_indexes)\n",
    "train_df = train_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "694a92c8-8a53-465b-86c0-d0fa573785b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df.drop([\"UserName\",\"ScreenName\",\"Location\",\"TweetAt\",\"OriginalTweet\",\"Sentiment\"],axis=1)\n",
    "y=train_df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a567f88e-5b8c-4684-9dbd-c4beed15d0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_prepro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coronaviru australia woolworth give elderli , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>food stock one empti pleas , n't panic , enoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>, readi go supermarket outbreak . 'm paranoid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news region first confirm covid case came sull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41114</th>\n",
       "      <td>airlin pilot offer stock supermarket shelv loc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41115</th>\n",
       "      <td>respons complaint provid cite covid relat dela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41116</th>\n",
       "      <td>know get tough ration toilet paper martinsvil ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41117</th>\n",
       "      <td>wrong smell hand sanit start turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41118</th>\n",
       "      <td>well new use rift go . amazon rn although norm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41119 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_prepro\n",
       "0      advic talk neighbour famili exchang phone numb...\n",
       "1      coronaviru australia woolworth give elderli , ...\n",
       "2      food stock one empti pleas , n't panic , enoug...\n",
       "3      , readi go supermarket outbreak . 'm paranoid ...\n",
       "4      news region first confirm covid case came sull...\n",
       "...                                                  ...\n",
       "41114  airlin pilot offer stock supermarket shelv loc...\n",
       "41115  respons complaint provid cite covid relat dela...\n",
       "41116  know get tough ration toilet paper martinsvil ...\n",
       "41117                  wrong smell hand sanit start turn\n",
       "41118  well new use rift go . amazon rn although norm...\n",
       "\n",
       "[41119 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b08cc76-6510-4ab7-a3e7-8b719d9bf97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Positive\n",
       "1                  Positive\n",
       "2                  Positive\n",
       "3        Extremely Negative\n",
       "4                  Positive\n",
       "                ...        \n",
       "41114               Neutral\n",
       "41115    Extremely Negative\n",
       "41116              Positive\n",
       "41117               Neutral\n",
       "41118              Negative\n",
       "Name: Sentiment, Length: 41119, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77ebe16-3b53-4610-8f77-791d0507b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_documents=[preprocess_text2(doc) for doc in X[\"text_prepro\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79bdb735-45c4-4efa-a278-875b2a13a012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41119"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a04219fa-7284-4ad7-80fa-c7e4695b7cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in ./anaconda3/lib/python3.11/site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./anaconda3/lib/python3.11/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./anaconda3/lib/python3.11/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in ./anaconda3/lib/python3.11/site-packages (from gensim) (5.2.1)\n",
      "Collecting FuzzyTM>=0.4.0 (from gensim)\n",
      "  Obtaining dependency information for FuzzyTM>=0.4.0 from https://files.pythonhosted.org/packages/2d/30/074bac7a25866a2807c1005c7852c0139ac22ba837871fc01f16df29b9dc/FuzzyTM-2.0.9-py3-none-any.whl.metadata\n",
      "  Downloading FuzzyTM-2.0.9-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.11/site-packages (from FuzzyTM>=0.4.0->gensim) (2.2.2)\n",
      "Collecting pyfume (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pyfume from https://files.pythonhosted.org/packages/ed/ea/a3b120e251145dcdb10777f2bc5f18b1496fd999d705a178c1b0ad947ce1/pyFUME-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading pyFUME-0.3.4-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/lib/python3.11/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Collecting scipy>=1.7.0 (from gensim)\n",
      "  Obtaining dependency information for scipy>=1.7.0 from https://files.pythonhosted.org/packages/0d/3e/d05b9de83677195886fb79844fcca19609a538db63b1790fa373155bc3cf/scipy-1.10.1-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading scipy-1.10.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.18.5 (from gensim)\n",
      "  Obtaining dependency information for numpy>=1.18.5 from https://files.pythonhosted.org/packages/c0/bc/77635c657a3668cf652806210b8662e1aff84b818a55ba88257abf6637a8/numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Collecting simpful==2.12.0 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for simpful==2.12.0 from https://files.pythonhosted.org/packages/9d/0e/aebc2fb0b0f481994179b2ee2b8e6bbf0894d971594688c018375e7076ea/simpful-2.12.0-py3-none-any.whl.metadata\n",
      "  Downloading simpful-2.12.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting fst-pso==1.8.1 (from pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas (from FuzzyTM>=0.4.0->gensim)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/b0/be/1843b9aff84b98899663e7cad9f45513dfdd11d69cb5bd85c648aaf6a8d4/pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting miniful (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim)\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Downloading FuzzyTM-2.0.9-py3-none-any.whl (31 kB)\n",
      "Downloading pyFUME-0.3.4-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp311-cp311-macosx_12_0_arm64.whl (28.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.7/28.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading simpful-2.12.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20430 sha256=16cd736d0f4dc28e12c4cc25c250ba1a8fae779fd19e966f0425b5059e431eb7\n",
      "  Stored in directory: /Users/mohitsarin/Library/Caches/pip/wheels/69/f5/e5/18ad53fe1ed6b2af9fad05ec052e4acbac8e92441df44bad2e\n",
      "  Building wheel for miniful (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3513 sha256=f03bb8219c9ba88f32f8f438751550720f572bd3c4a6b21c6e7e0873698a48db\n",
      "  Stored in directory: /Users/mohitsarin/Library/Caches/pip/wheels/9d/ff/2f/afe4cd56f47de147407705626517d68bea0f3b74eb1fb168e6\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: numpy, scipy, pandas, simpful, miniful, fst-pso, pyfume, FuzzyTM\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.14.0\n",
      "    Uninstalling scipy-1.14.0:\n",
      "      Successfully uninstalled scipy-1.14.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "findpeaks 2.6.3 requires scipy==1.11.4, but you have scipy 1.10.1 which is incompatible.\n",
      "recbole 1.2.0 requires colorama==0.4.4, but you have colorama 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed FuzzyTM-2.0.9 fst-pso-1.8.1 miniful-0.0.6 numpy-1.24.4 pandas-1.5.3 pyfume-0.3.4 scipy-1.10.1 simpful-2.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a86c6148-a6ee-4904-9be3-f0661dbbe7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "697f66e4-ea70-48ed-b0a3-3235ba129108",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukuran_vektor=100\n",
    "word2vec_model = Word2Vec(sentences=tokenized_documents, \n",
    "                          min_count=1, vector_size=ukuran_vektor,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "248945a5-539e-4d7f-84cd-bbac41b7f81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=22831, vector_size=100, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82c0eb32-33cc-4f5e-89cb-adf1c073cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words =word2vec_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "386f302a-306c-4fa4-ae15-3f34fbc05e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". : 0\n",
      ", : 1\n",
      "covid : 2\n",
      "price : 3\n",
      "store : 4\n",
      "supermarket : 5\n",
      "food : 6\n",
      "groceri : 7\n",
      "peopl : 8\n",
      "amp : 9\n",
      "consum : 10\n",
      "shop : 11\n",
      "go : 12\n",
      "get : 13\n",
      "need : 14\n",
      "'s : 15\n",
      "onlin : 16\n",
      "time : 17\n",
      "buy : 18\n",
      "work : 19\n",
      "worker : 20\n",
      "hand : 21\n",
      "pandem : 22\n",
      "like : 23\n",
      "help : 24\n",
      "sanit : 25\n",
      "stock : 26\n",
      "panic : 27\n",
      "home : 28\n",
      "n't : 29\n",
      "demand : 30\n",
      "us : 31\n",
      "coronaviru : 32\n",
      "one : 33\n",
      "make : 34\n",
      "suppli : 35\n",
      "day : 36\n",
      "take : 37\n",
      "due : 38\n",
      "use : 39\n",
      "keep : 40\n",
      "mask : 41\n",
      "week : 42\n",
      "plea : 43\n",
      "new : 44\n",
      "stay : 45\n",
      "see : 46\n",
      "busi : 47\n",
      "market : 48\n",
      "crisi : 49\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(all_words):\n",
    "    if index < 50:\n",
    "        print(f\"{word} : {index}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2de36f6c-d1fd-455e-b767-e234206c62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length =train_df['text_prepro'].apply(lambda x: len(x.split())).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4d7b827-461a-4e32-a0f1-18967048824e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c93983b5-0df1-4d68-b76b-93b79247e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length Index : 37122\n"
     ]
    }
   ],
   "source": [
    "max_length_index = train_df['text_prepro'].apply(len).idxmax()\n",
    "print(\"Max Length Index :\", max_length_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35a098b1-f29e-435d-8f95-e993a9f17c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nisan cumartesi itibariyl bb nin hizmetleri soka kma serbestisi olanlar devam edecek . halk ekmek hamidiy su retim ge ti . bb , stanbul un g da ihtiyac na yetecek kapasitededir . halk z sakin olsun g vend hissetsin . l tfen herk evin ns n .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.at[max_length_index, 'text_prepro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a3191bf-957d-4acd-b6b8-a8afbc4d4f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' nisan cumartesi itibariyle bb nin t m hizmetleri soka a kma serbestisi olanlar i in devam edecek. halk ekmek ve hamidiye su retime ge ti. bb, t m stanbul un g da ihtiyac na yetecek kapasitededir. halk m z sakin olsun ve g vende hissetsin. l tfen herkes evine d ns n.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.at[max_length_index, 'OriginalTweet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20537544-92b8-4923-bd9c-074299d447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[word2vec_model.wv.key_to_index[word] for word in text] \n",
    "             for text in [preprocess_text2(doc) for doc in X['text_prepro']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c64231a0-e784-48ee-b43d-e7526a51e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[452,\n",
       " 318,\n",
       " 1377,\n",
       " 115,\n",
       " 1872,\n",
       " 651,\n",
       " 308,\n",
       " 340,\n",
       " 329,\n",
       " 242,\n",
       " 651,\n",
       " 308,\n",
       " 1377,\n",
       " 409,\n",
       " 72,\n",
       " 1801,\n",
       " 2861,\n",
       " 346,\n",
       " 16,\n",
       " 11,\n",
       " 746,\n",
       " 8668,\n",
       " 2095,\n",
       " 35,\n",
       " 912,\n",
       " 1867,\n",
       " 86]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e80446fc-cc2c-490c-800d-ce4b7efca84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97c4a208-578b-4d39-91ff-3e314468656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca269b85-3713-45f1-ba95-041a008191aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 452,  318, 1377, ...,    0,    0,    0],\n",
       "       [  32,  692, 3230, ...,    0,    0,    0],\n",
       "       [   6,   26,   33, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  67,   13, 1326, ...,    0,    0,    0],\n",
       "       [ 612, 2252,   21, ...,    0,    0,    0],\n",
       "       [ 132,   44,   39, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78304111-a91f-4d94-bb6c-d5d72ecd1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35256dfb-5131-4f7b-b00c-5f0d2d260c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e7e7425-a8dc-465e-bc52-35603464d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val=train_test_split(padded_sequences,y,\n",
    "                    test_size=0.2,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfbaa68f-7e4f-48cc-9ffd-87b18ccffc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word2vec_model.wv.key_to_index) + 1, word2vec_model.vector_size))\n",
    "for word, i in word2vec_model.wv.key_to_index.items():\n",
    "    embedding_vector = word2vec_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "986de319-1792-4da2-8e9f-919b9cdcd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes=len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87aba128-04dc-45d5-b015-1b057b60bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, MultiHeadAttention, GlobalMaxPooling1D, LayerNormalization, Dropout\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5edbb238-eea7-49a4-85e7-44bc81535bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transformer_model(max_length, vocab_size, embedding_dim, num_heads, ff_dim, num_classes):\n",
    "    inputs = Input(shape=(max_length,))\n",
    "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "    x = Dropout(0.3)(embedding)\n",
    "    multi_head_attention = MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
    "    x = multi_head_attention(query=x, value=x, key=x)\n",
    "    x = LayerNormalization()(x)\n",
    "    ff_network = Dense(ff_dim, activation='relu', kernel_regularizer=l2(0.01))(x) \n",
    "    ff_network = Dense(embedding_dim, kernel_regularizer=l2(0.01))(ff_network)\n",
    "    x = x + ff_network\n",
    "    x = LayerNormalization()(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x) \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5e875cb0-141c-4aba-850b-479e0a4fa413",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max_length\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "embedding_dim = embedding_matrix.shape[1]\n",
    "num_heads = 8\n",
    "ff_dim = 256\n",
    "num_classes = number_of_classes\n",
    "model = build_transformer_model(max_length, vocab_size, embedding_dim, num_heads, ff_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "839deefb-01d3-4b42-9474-c7caa3be0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', \n",
    "                                                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ed526f5-53f4-4cce-8ae9-b5e83f746218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, \n",
    "                                     restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ab23e-32b0-486f-99e3-2a878d9eb7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "129/129 [==============================] - 87s 665ms/step - loss: 3.3619 - accuracy: 0.2394 - val_loss: 2.3188 - val_accuracy: 0.2471\n",
      "Epoch 2/1500\n",
      "129/129 [==============================] - 84s 649ms/step - loss: 1.6100 - accuracy: 0.5134 - val_loss: 1.0705 - val_accuracy: 0.6860\n",
      "Epoch 3/1500\n",
      "129/129 [==============================] - 92s 711ms/step - loss: 0.8966 - accuracy: 0.7280 - val_loss: 0.8514 - val_accuracy: 0.7180\n",
      "Epoch 4/1500\n",
      "129/129 [==============================] - 101s 784ms/step - loss: 0.6645 - accuracy: 0.7849 - val_loss: 0.7928 - val_accuracy: 0.7241\n",
      "Epoch 5/1500\n",
      "129/129 [==============================] - 78s 606ms/step - loss: 0.5375 - accuracy: 0.8215 - val_loss: 0.8200 - val_accuracy: 0.7049\n",
      "Epoch 6/1500\n",
      "129/129 [==============================] - 80s 622ms/step - loss: 0.4464 - accuracy: 0.8489 - val_loss: 0.8797 - val_accuracy: 0.7005\n",
      "Epoch 7/1500\n",
      "129/129 [==============================] - 76s 590ms/step - loss: 0.3795 - accuracy: 0.8691 - val_loss: 0.9902 - val_accuracy: 0.6752\n",
      "Epoch 8/1500\n",
      "129/129 [==============================] - 71s 547ms/step - loss: 0.3370 - accuracy: 0.8834 - val_loss: 1.0256 - val_accuracy: 0.6734\n",
      "Epoch 9/1500\n",
      "129/129 [==============================] - 70s 545ms/step - loss: 0.2977 - accuracy: 0.8964 - val_loss: 1.0756 - val_accuracy: 0.6707\n",
      "Epoch 10/1500\n",
      "129/129 [==============================] - 81s 626ms/step - loss: 0.2728 - accuracy: 0.9061 - val_loss: 1.1991 - val_accuracy: 0.6640\n",
      "Epoch 11/1500\n",
      "129/129 [==============================] - 79s 611ms/step - loss: 0.2576 - accuracy: 0.9114 - val_loss: 1.2311 - val_accuracy: 0.6522\n",
      "Epoch 12/1500\n",
      "129/129 [==============================] - 81s 630ms/step - loss: 0.2342 - accuracy: 0.9176 - val_loss: 1.2879 - val_accuracy: 0.6486\n",
      "Epoch 13/1500\n",
      "129/129 [==============================] - 98s 756ms/step - loss: 0.2185 - accuracy: 0.9243 - val_loss: 1.3743 - val_accuracy: 0.6446\n",
      "Epoch 14/1500\n",
      "129/129 [==============================] - 81s 630ms/step - loss: 0.2064 - accuracy: 0.9266 - val_loss: 1.4482 - val_accuracy: 0.6356\n",
      "Epoch 15/1500\n",
      "129/129 [==============================] - 81s 625ms/step - loss: 0.1955 - accuracy: 0.9313 - val_loss: 1.4710 - val_accuracy: 0.6417\n",
      "Epoch 16/1500\n",
      "129/129 [==============================] - 75s 581ms/step - loss: 0.1921 - accuracy: 0.9332 - val_loss: 1.5259 - val_accuracy: 0.6305\n",
      "Epoch 17/1500\n",
      "129/129 [==============================] - 82s 634ms/step - loss: 0.1804 - accuracy: 0.9369 - val_loss: 1.6330 - val_accuracy: 0.6340\n",
      "Epoch 18/1500\n",
      "129/129 [==============================] - 76s 589ms/step - loss: 0.1746 - accuracy: 0.9390 - val_loss: 1.6648 - val_accuracy: 0.6342\n",
      "Epoch 19/1500\n",
      " 75/129 [================>.............] - ETA: 45s - loss: 0.1620 - accuracy: 0.9424"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1500, batch_size=256, \n",
    "                    validation_data=(X_val, y_val), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400b44a-eb4f-41ac-9ac2-aad6f56f79e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6ea26e-6b31-4a7b-8c9e-7be6ae0a2358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
